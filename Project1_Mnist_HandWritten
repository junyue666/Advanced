import tensorflow as tf
mnist = tf.keras.datasets.mnist
(x_,y_),(x_1,y_1) = mnist.load_data()   #import data(导入数据)

#对数据进行可视化
import matplotlib.pyplot as plt
for i range(36):
    plt.subplot(6,6,i+1)
    plt.imshow(x_[i])
plt.show()

#将图像从本身的【 ，28，28】转成【 ，784】
X_= x_.reshape(60000,784)
X_1 = x_1.reshae(10000,784)

#将数据类型转换成float32
X_train = X_.astype("float32")
X_train_1 = X_.astype("float32")
#将数据归一化
X_train /=255
X_train_1 /=255

import numpy as np

#统计标签的数目
label,counts = np.unique(y_,return_counts=True)
label_1,counts_1 = np.unique(y_1,return_counts=True)
#标签及数目可视化
plt.bar(label,counts)
plt.title("The distribution of label")
for a,b in zip(label,counts):
    plt.text(a,b,"%d"%b,ha="center",va="bottom")
plt.show()

import np_utils
from  keras.utils.np_utils import to_categorical

#进行one-hot编码（不知道为什么）
n_classes = 10
print("Shape before one-hot encoding",y_.shape)
Y_ = to_categorical(y_,n_classes)
print("Shape after one-hot encoding",Y_,shape)
Y_1 = to_categorical(y_1,n_classes)

#定义Mnist CNN网络

import tensorflow as tf
from keras.models import Sequential
from keras.layers.core import Dense,Dropout,Flatten
from keras.layers import Conv2D,MaxPool2D

#实例化
model = Sequential()

#第一层卷积，32个3*3的卷积核，激活函数是ReLu
model.add(Conv2D(filter=32,kerne_size=(3,3),activation='relu',input_shape=input_shape))#这里的input_shape不太清楚代表什么
#第二层卷积，64个3*3的卷积核，激活函数是ReLu
model.add(Conv2D(filters=64,kernel_size=(3,3),activation="relu"))
#最大池化层，池化窗口2*2
model.add(MaxPool2D(pool_size=(2,2)))

#Dropout25%的输入神经元
model.add(Dropout(0.25))

#将Pooled feature map摊平后输入到全连接网络
model(Flatten())

#Classification
#全连接层
model.add(Dense(128,activation="relu))

#Dropout 50%的输入神经
model.add(Dropout(0.5))

#查看Mnist CNN模型网络结构
model.summary()

for layer in model.layers:
print(layer.get_output_at(0).get_shape().as_list())

#编译模型
model.compile(loss="categorical_crossentropy",metrics=["accuracy"],optimizer="adam")
